import re, html, requests
from config.settings import STATUS_MAPPING

# Helper function ƒë·ªÉ tr√°nh l·∫∑p code
def _make_request(url, method='get', **kwargs):
    print(f"  üîó Requesting URL: {url}")
    try:
        if method == 'post':
            response = requests.post(url, timeout=20, **kwargs)
        else:
            response = requests.get(url, timeout=20, **kwargs)
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        print(f"  ‚ùå Request failed: {e}")
        return None

def scrape_japanpost(no: str) -> str:
    print(f"   scraping Japan Post...")
    kind = "S004" if re.match(r"^[A-Za-z]{2}\d{9}JP$", no) else "S002"
    url = f"https://trackings.post.japanpost.jp/services/srv/search/direct?reqCodeNo1={no}&searchKind={kind}&locale=ja"
    
    r = _make_request(url)
    if not r: return "Kh√¥ng t√¨m th·∫•y m√£ v·∫≠n ƒë∆°n n√†y"

    tbl = re.search(r'<table[^>]*summary="Â±•Ê≠¥ÊÉÖÂ†±"[^>]*>(.*?)</table>', r.text, re.DOTALL)
    if not tbl:
        print("  ‚ùå Could not find status table on page.")
        return "Kh√¥ng t√¨m th·∫•y m√£ v·∫≠n ƒë∆°n n√†y"

    sts = re.findall(r'<td[^>]*class="w_150"[^>]*>(.*?)</td>', tbl.group(1), re.DOTALL)
    clean = [re.sub(r"<[^>]+>", "", s).strip() for s in sts]
    
    if not clean:
        print("  ‚ùå Found table, but no status entries inside.")
        return "Kh√¥ng t√¨m th·∫•y m√£ v·∫≠n ƒë∆°n n√†y"
    
    original_status = clean[-1]
    print(f"  ‚úÖ Found raw status: '{original_status}'")
    return STATUS_MAPPING.get(original_status, original_status)

def scrape_yamato(no: str) -> str:
    print(f"  scraping Yamato...")
    url = "https://toi.kuronekoyamato.co.jp/cgi-bin/tneko"
    
    r = _make_request(url, method='post', data={"number01": no})
    if not r: return "L·ªói k·∫øt n·ªëi"

    m = re.search(r'<h4[^>]*class="tracking-invoice-block-state-title"[^>]*>(.*?)</h4>', r.text, re.DOTALL)
    if not m:
        print("  ‚ùå Could not find status element on page.")
        return "Sai m√£ b∆∞u ƒëi·ªán"
    
    original_status = m.group(1).strip()
    print(f"  ‚úÖ Found raw status: '{original_status}'")
    return STATUS_MAPPING.get(original_status, original_status)

def scrape_sagawa(no: str) -> str:
    print(f"  scraping Sagawa...")
    url = f"https://k2k.sagawa-exp.co.jp/p/web/okurijosearch.do?okurijoNo={no}"

    r = _make_request(url)
    if not r: return "L·ªói k·∫øt n·ªëi"
    
    r.encoding = "cp932"
    m = re.search(r'<span class="state">([^<]+)', r.text)
    
    if not m:
        print("  ‚ùå Could not find status element on page.")
        return "Sai m√£ b∆∞u ƒëi·ªán"
    
    original_status = html.unescape(m.group(1).strip())
    print(f"  ‚úÖ Found raw status: '{original_status}'")
    return STATUS_MAPPING.get(original_status, original_status)
